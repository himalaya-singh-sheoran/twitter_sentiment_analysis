{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754068b-9bb1-46bb-9f42-04b1c84fa530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import notebook\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711996e-5cc0-4528-8e2e-f11106af26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data is in form of a database\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import sqlalchemy \n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(\"lockdown1.db\")    \n",
    "    #Now in order to read in pandas dataframe we need to know table name\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT * FROM geo;\")\n",
    "    #print(f\"Table Name : {cursor.fetchall()}\")\n",
    "    df = pd.read_sql_query('SELECT * FROM geo', conn)\n",
    "    df.head()\n",
    "    conn.close()\n",
    "\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab8b5b9-cde4-478b-af38-e0e4c8d7cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_files.txt',names=['tweet_id','sentiment_score']) \n",
    "# in combined_files.txt files I stored tweet_ids and sentiment scores of all the tweets\n",
    "df.sort_values(['tweet_id'],inplace =True)\n",
    "df.reset_index(drop=True,inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a2677-f679-4c83-b629-b93ff0b188c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "#get your keys using twitter account\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b742edd-fd5e-4a35-b530-b6a17c09162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = api.statuses_lookup([1248458710189363204], tweet_mode='extended') #get the entire tweet text\n",
    "print(tweets[0].id) #displays tweet id\n",
    "print(tweets[0].full_text) #displays the tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5d1b3-007c-47cb-af57-e072d2e905ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = list(df.tweet_id)\n",
    "t_ids = [] #if tweet of a corresponding id is found then it's tweet_id will be stored here\n",
    "t_texts = [] #if tweet of a corresponding id is found then it's tweet text will be stored here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742140b-cb19-4bf5-9482-35ddda19370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first index where to start downloading tweets\n",
    "# As it takes a lot of time to download tweets (as you can request only around 100 tweets per request)\n",
    "#So if you had to stop training at some point just put first_idx to index in 'tweet_ids' list from where you want to continue\n",
    "first_idx = 0\n",
    "end_idx = first_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c7af2-ea03-4967-b162-d130c005f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False\n",
    "while end_idx <= df.shape[0]:\n",
    "    if end_idx +100 >  df.shape[0]:\n",
    "        end_idx = df.shape[0]\n",
    "        flag=True\n",
    "    else:\n",
    "        end_idx += 100\n",
    "        \n",
    "    print(end_idx,end=\",\")\n",
    "    tmp = api.statuses_lookup(tweet_ids[first_idx:end_idx], tweet_mode='extended')\n",
    "    tmp_ids = []\n",
    "    tmp_tweets = []\n",
    "    for x in tmp:\n",
    "        tmp_ids.append(x.id)\n",
    "        tmp_tweets.append(x.full_text)\n",
    "    t_texts += tmp_tweets\n",
    "    t_ids += tmp_ids\n",
    "    first_idx = end_idx\n",
    "    if flag:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12632aad-6bc9-4e27-8404-12487239201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to store tweet_ids and corresponding text if you wish to stop downloading\n",
    "import pickle\n",
    "with open('ids.pkl', 'wb') as f:\n",
    "    pickle.dump(t_ids, f)\n",
    "with open('texts.pkl', 'wb') as f:\n",
    "    pickle.dump(t_texts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4340401-e4dd-4b41-8fc2-3290c8be362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load previously downloaded tweets\n",
    "with open('ids.pkl', 'rb') as f:\n",
    "    t_ids1 = pickle.load(f)\n",
    "\n",
    "    \n",
    "with open('texts.pkl', 'rb') as f:\n",
    "    t_texts1 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3c656-5e81-4025-82cb-1acb06d65a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you had multiple checkpoints\n",
    "all_t_ids = t_ids1+t_ids2+t_ids\n",
    "all_t_texts = t_texts1+t_texts2+t_texts\n",
    "len(all_t_ids),len(all_t_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb53e8f-728c-44b2-b2f0-59b0b8bdb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame({'tweet_id':all_t_ids,'text':all_t_texts})\n",
    "dfx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c51848a-e9b6-41ca-84ec-dcd1b2bade26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiment scores of tweets of which text was found\n",
    "df_p = 0\n",
    "for i in notebook.tqdm(range(dfx.shape[0])):\n",
    "    if dfx.tweet_id[i] == df.tweet_id[df_p]:\n",
    "        sscores.append(df.sentiment_score[df_p])\n",
    "        df_p+=1\n",
    "    elif dfx.tweet_id[i] > df.tweet_id[i]:\n",
    "        while True:\n",
    "            df_p+=1\n",
    "            if dfx.tweet_id[i] == df.tweet_id[df_p]:\n",
    "                sscores.append(df.sentiment_score[df_p])\n",
    "                df_p+=1\n",
    "                break         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9c5bb-8ac2-4875-be92-bd5976156115",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx.sentiment_score = sscores #makes a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e0b31-a8b2-4a65-a4c9-e55689a7da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx.to_csv('tweets_downloaded.csv',index =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
